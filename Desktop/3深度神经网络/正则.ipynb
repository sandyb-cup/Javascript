{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T09:55:45.946833Z",
     "start_time": "2020-09-26T09:55:45.625438Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from testCases import *\n",
    "from dnn_utils import *\n",
    "\n",
    "# 设置一些图画的相关参数\n",
    "%matplotlib inline\n",
    "\n",
    "# 图像的大小\n",
    "plt.rcParams[\"figure.figsize\"] = (5.0, 4.0)\n",
    "# 图像位置\n",
    "plt.rcParams['image.interpolation'] = 'nearset'\n",
    "# 图像颜色\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# 设置随机函数\n",
    "np.random.seed(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T09:55:45.975506Z",
     "start_time": "2020-09-26T09:55:45.948773Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x_orig.shape (209, 64, 64, 3)\n",
      "train_y_orig.shape (1, 209)\n",
      "test_x_orig.shape (50, 64, 64, 3)\n",
      "test_y_orig.shape (1, 50)\n",
      "classes [b'non-cat' b'cat']\n"
     ]
    }
   ],
   "source": [
    "train_x_orig, train_y_orig, test_x_orig, test_y_orig,classes = load_data()\n",
    "print('train_x_orig.shape',train_x_orig.shape)\n",
    "print('train_y_orig.shape',train_y_orig.shape)\n",
    "print('test_x_orig.shape',test_x_orig.shape)\n",
    "print('test_y_orig.shape',test_y_orig.shape)\n",
    "print('classes', classes)\n",
    "\n",
    "train_x = train_x_orig.reshape(train_x_orig.shape[0],-1).T/255\n",
    "train_y = train_y_orig\n",
    "\n",
    "test_x = test_x_orig.reshape(test_x_orig.shape[0],-1).T/255\n",
    "test_y = test_y_orig \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T09:55:45.984236Z",
     "start_time": "2020-09-26T09:55:45.979029Z"
    }
   },
   "outputs": [],
   "source": [
    "def initialize(dim_info): # 初始化函数 初始化W b的值\n",
    "\n",
    "    np.random.seed(1)\n",
    "    # dim_info 是一个列表里面包含了每一层的神经元的个数 比如说dim_info=[12288, 10, 7, 1]\n",
    "    # 第一层的神经元个数是 10， 第二层神经元个数是：7 ，输出层的神经元个数是：1\n",
    "    parameters = {} # 创建储存字典parameters\n",
    "    \n",
    "    dim_len = len(dim_info) # 得出有多少层神经网络\n",
    "    \n",
    "    # 开始有for循环来初始化参数 举例w[i,for i range(1,len(dim_info)),i-1]\n",
    "    # 得出w1 = (? , 12288) \n",
    "    # 得出的b的维度是:b(?, 1)\n",
    "    # 各个层的维度信息:\n",
    "    # z = (w * x) + b\n",
    "    # w * x = (?, temp_num)\n",
    "    # b = (?, 1)\n",
    "    # z = (?, temp_num)\n",
    "    # a = sidmoid(z)\n",
    "     \n",
    "    # 用for循环来随机初始化w，b\n",
    "    for l in range(1, dim_len):\n",
    "        parameters['W'+ str(l)] = np.random.randn(dim_info[l], dim_info[l-1]) *np.sqrt(2/dim_info[l-1])\n",
    "        # 防止梯度爆炸使w的值更小一些 除以前面神经元个数的开方\n",
    "        parameters['b'+ str(l)] = np.zeros((dim_info[l],1))\n",
    "        \n",
    "    return parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T09:55:46.002733Z",
     "start_time": "2020-09-26T09:55:45.986347Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 12288)\n",
      "(30, 1)\n",
      "(8, 30)\n",
      "(8, 1)\n"
     ]
    }
   ],
   "source": [
    "dim_info = [12288, 30, 8, 6, 1]\n",
    "parameters = initialize(dim_info)\n",
    "print(parameters['W1'].shape)\n",
    "print(parameters['b1'].shape)\n",
    "print(parameters['W2'].shape)\n",
    "print(parameters['b2'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T09:55:46.008307Z",
     "start_time": "2020-09-26T09:55:46.004911Z"
    }
   },
   "outputs": [],
   "source": [
    "def line_forward(A, W, b):\n",
    "\n",
    "    Z = np.dot(W, A)+b\n",
    "    \n",
    "    assert W.shape[1] == A.shape[0]\n",
    "    \n",
    "    assert b.shape == (W.shape[0],1)\n",
    "    \n",
    "    \n",
    "    forward_Z_parameters = (A, W, b)\n",
    "    \n",
    "    \n",
    "    return Z, forward_Z_parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T09:55:46.014411Z",
     "start_time": "2020-09-26T09:55:46.010282Z"
    }
   },
   "outputs": [],
   "source": [
    "# 前向传播激活函数层 选择激活函数\n",
    "def line_activate(A_prev, W, b, activation):\n",
    "    # \n",
    "    \n",
    "    Z, forward_Z_parameters_cache = line_forward(A_prev, W, b) # 前向传播公式\n",
    "    # forwars_Z_parameters_cache中包含了这一层的a,w,b 参数\n",
    "    # cache 向前传播的返回的w,a_prev,b值\n",
    "    \n",
    "    if activation == 'sigmoid':\n",
    "        A = sigmoid(Z) \n",
    "        \n",
    "        # 激活函数这里不要被上面的a混淆了 这里的A是本层计算出来的激活值\n",
    "        \n",
    "    else: \n",
    "        activation == 'relu'\n",
    "        A = relu(Z)\n",
    "        \n",
    "    forward_activate_parameters_Z = (forward_Z_parameters_cache, Z)\n",
    "    \n",
    "    \n",
    "    # 储存本层所用到的计算参数 W，a-1，b,跟计算出来的逻辑回归值 z\n",
    "    # 这些参数在反向传播中用得到\n",
    "    # 反向传播时要用到的参数 z在激活函数的偏导数是要用到，\n",
    "    # w 在计算z的偏导数时候要用到\n",
    "    # a 在计算w的偏导数是要用到\n",
    "    # b 在计算b的偏导数是要用到\n",
    "    \n",
    "    return A, forward_activate_parameters_Z, \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T09:55:46.020777Z",
     "start_time": "2020-09-26T09:55:46.015921Z"
    }
   },
   "outputs": [],
   "source": [
    "def line_model(X, parameters):\n",
    "    # 构造成整一个的前向传播函数\n",
    "    # parameters 这个参数包含了每一层的w， b 也就是每一层的w，b\n",
    "    # print(\"parameters['w1']\",parameters['w1'].shape)\n",
    "    froward_model_cache = []\n",
    "    \n",
    "    A = X \n",
    "    \n",
    "    layer_deep = len(parameters)//2\n",
    "    # print('layer_deep',layer_deep)\n",
    "    \n",
    "    # 神经层数会等于是parameters除以二取整数 因为里面包含的是w，b参数\n",
    "    \n",
    "    for i in range(1,layer_deep):\n",
    "        A_prev = A\n",
    "        # 前面的layer_deep - 1 层用sigmoid激活函数\n",
    "        \n",
    "        A, forward_activate_parameters_Z = line_activate(A_prev, parameters['W'+str(i)], parameters['b'+str(i)], activation = 'rule')\n",
    "        \n",
    "        # 注意这个看得到的A是这一步算出来的A 值 而cache里面包含的A_prev是上一步的a\n",
    "        \n",
    "        # 这里在后面的反向传播中不要弄混了\n",
    "        \n",
    "        # 这个循环不包括最后一层的前向传播 这前面的前向传播激活函数是sigmod\n",
    "        \n",
    "        # 进行数据的储存也就是这一层所用到的参数 W,a-1,b,z \n",
    "        \n",
    "        froward_model_cache.append(forward_activate_parameters_Z)\n",
    "    \n",
    "    # print('A_shape.shape',A.shape)\n",
    "    \n",
    "    # print('w4',parameters['w4'].shape)\n",
    "    \n",
    "    Al, forward_activate_parameters_Z = line_activate(A, parameters['W'+str(layer_deep)],parameters['b'+str(layer_deep)], activation = 'sigmoid')\n",
    "    \n",
    "    # 进行最后一层的向前传播\n",
    "    \n",
    "    froward_model_cache.append(forward_activate_parameters_Z) \n",
    "    \n",
    "    # 储存上一步的w,a,b 这里的上一步是针对于最后一步来说的也就是用sigmoid激活函数那一层\n",
    "    \n",
    "    # cache 里面包含 w,b,a等参数 用于反向传播 前一步的w，b, a 最后的一步al才是最后面的sigmoid函数计算出来的值\n",
    "    \n",
    "    # print('ilne_model_Al.shape',Al.shape)\n",
    "    \n",
    "    return Al,  froward_model_cache\n",
    "    \n",
    "    \n",
    "    \n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T09:55:46.027178Z",
     "start_time": "2020-09-26T09:55:46.023495Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Al[[0.17007265 0.2524272 ]]\n",
      "Length of caches list=2\n"
     ]
    }
   ],
   "source": [
    "X, parameters = L_model_forward_test_case()\n",
    "Al, caches = line_model(X, parameters)\n",
    "print('Al'+str(Al))\n",
    "print('Length of caches list='+str(len(caches)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T09:55:46.032455Z",
     "start_time": "2020-09-26T09:55:46.029259Z"
    }
   },
   "outputs": [],
   "source": [
    "def computer_cost(al, y):\n",
    "    \n",
    "    # 去样本值进行后面的求值计算\n",
    "\n",
    "    m = y.shape[1]\n",
    "\n",
    "    cost = (-1/m) * np.sum(np.multiply(y, np.log(al)) + np.multiply(1 - y,np.log(1-al))) \n",
    "\n",
    "    # cost = np.squeeze(cost) \n",
    "    # 对cost进行去维度化\n",
    "    # print('computer_cost.shape', cost.shape)\n",
    "    \n",
    "    \n",
    "    return cost\n",
    "\n",
    "                           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"burk\"># cost加上正则</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T09:55:46.039376Z",
     "start_time": "2020-09-26T09:55:46.033871Z"
    }
   },
   "outputs": [],
   "source": [
    "def cost_L2_tail(cost, forward_parameters, lambda_num, m):\n",
    "    \n",
    "    parameters = {}\n",
    "    \n",
    "    arr = np.array(forward_parameters) # 将正向传播参数矩阵化\n",
    "    \n",
    "    L = arr.shape[0] # 提取网络层数\n",
    "    \n",
    "    for l in range(L):\n",
    "        parameters[\"W\"+str(l+1)] = arr[l][0][1] # 进行正向传播单个参数进行提取 \n",
    "    \n",
    "        parameters[\"b\"+str(l+1)] = arr[l][0][2] # 与上面同理\n",
    "    \n",
    "    L2 = 0\n",
    "    \n",
    "    for L in range(L): # 对正向传播参数W进行平方计算\n",
    "        L2 += np.sum(np.square(parameters[\"W\"+str(L+1)]))\n",
    "        \n",
    "    L2_regulariztion_cost = lambda_num * L2 / (2 * m) + cost # cost加上L2正则运算\n",
    "\n",
    "    return L2_regulariztion_cost, parameters\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T09:55:46.044614Z",
     "start_time": "2020-09-26T09:55:46.040797Z"
    }
   },
   "outputs": [],
   "source": [
    "def back_forward(dz, forward_Z_parameters):\n",
    "    \n",
    "    \n",
    "    a_prev, w, b = forward_Z_parameters \n",
    "    \n",
    "    m = a_prev.shape[1]\n",
    "    # 这一层样本数 \n",
    "    \n",
    "    # dz 最后一层的损失dz梯度\n",
    "    # cache 前向传播时保存下来的参数值 分别是a,w,b\n",
    "    \n",
    "    # dz.shape(1, 209)\n",
    "    # a.shape(12288, 209)\n",
    "    # 这个a在输入层的话就是x所以他的维度信息就可以得出来就是 (12288, 209)\n",
    "    # 在反向传播中进行倒置 与dz相乘得到dw.shape(1, 12288)\n",
    "    \n",
    "    dW = np.dot(dz, forward_Z_parameters[0].T)/m \n",
    "    # dz = (1,209),a_prev.shape(1,1)\n",
    "    # dw.shape(1, 209)\n",
    "    \n",
    "    db = np.sum(dz, axis = 1, keepdims=True)/m \n",
    "    # 以列为轴将每一行的数据进行相加\n",
    "    \n",
    "    dA = np.dot(forward_Z_parameters[1].T, dz)\n",
    "    # da (a的偏导数等于w*dz)\n",
    "    # w.shape(1, 209)\n",
    "    # dz.shape(1, 209)\n",
    "    # da.shape(1,1)\n",
    "    \n",
    "    return dA, dW, db\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T09:55:46.050860Z",
     "start_time": "2020-09-26T09:55:46.046774Z"
    }
   },
   "outputs": [],
   "source": [
    "def line_activation_backward(dA, forward_model_cache, activation):\n",
    "    \"\"\"\n",
    "    da 这一层的da也就是最后一层da值\n",
    "    cache = 向前传播时这一层的相关变量\n",
    "    activation  指示该层使用什么激活函数 \"sigmoid\"或者是\"relu\"\n",
    "    \n",
    "    \"\"\"\n",
    "    linear_caches, activation_cache = forward_model_cache\n",
    "    # da,dw,db,Z\n",
    "    if activation == 'relu':\n",
    "        dz = relu_backward(dA, activation_cache)\n",
    "        # 上一步的dz等于这一步的dz乘以上一步的da\n",
    "        # 这一层的dz会等于al的偏导数乘以a的偏导数\n",
    "    elif activation =='sigmoid': \n",
    "#         sigmoid偏导数等于a(1-a)\n",
    "#         tanh偏导数等于1-a*a\n",
    "        dz = sigmoid_backward(dA, activation_cache)\n",
    "    \n",
    "    # 根据这一层的dz算出这一层的dw，db以及前一层的da\n",
    "    da_prev, dw, db = back_forward(dz, linear_caches)\n",
    "    \n",
    "    return da_prev, dw, db\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T09:55:46.058609Z",
     "start_time": "2020-09-26T09:55:46.052244Z"
    }
   },
   "outputs": [],
   "source": [
    "# 下面构建出整个反向传播公式\n",
    "def line_model_backward(Al, y, forward_model_cache):\n",
    "    # al 最后一层的al值也就是预测值 cache是每一层储存相关参数\n",
    "    \n",
    "    # print(\"line_model_backward-foward_model_cache\", forward_model_cache)\n",
    "    \n",
    "    grades = {}\n",
    "    \n",
    "    l = len(forward_model_cache)\n",
    "    \n",
    "    m = y.shape[1]\n",
    "    # print('line_model_backward_m',m)\n",
    "    \n",
    "    y = y.reshape(Al.shape) # 使真实标签与预测值标签的维度保持一样方便后面的dal计算\n",
    "        \n",
    "    dal = -(np.divide(y,Al) - np.divide(1-y, 1-Al))\n",
    "    \n",
    "    # 计算最后一层的dw, db 因为最后一层使用的是sigmoid，可以直接算出dw跟db的值\n",
    "    \n",
    "    last_layer_parameters = forward_model_cache[-1]\n",
    "    \n",
    "    grades['dA'+str(l-1)], grades['dW'+str(l)], grades['db'+str(l)] = line_activation_backward(dal, last_layer_parameters, activation='sigmoid')\n",
    "    \n",
    "    # grades['dW'+str(l)] = grades[\"dW\"+str(l)] +\n",
    "    \n",
    "    # 这个revered函数会将循环的数进行倒置\n",
    "    \n",
    "    for i in reversed(range(1,l)):\n",
    "        grades['dA'+str(i - 1)], grades['dW'+str(i)],grades['db'+str(i)] = line_activation_backward(grades[\"dA\"+str(i)],\n",
    "                                                                                               forward_model_cache[i-1],\n",
    "                                                                                              activation = 'relu')\n",
    "        \n",
    "        # 这个for循环不会包含l的值所以这里计算的偏导数也就不包含最后一步的偏导数\n",
    "    return grades\n",
    "                                     \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T09:40:09.385409Z",
     "start_time": "2020-09-25T09:40:09.380007Z"
    }
   },
   "source": [
    "<span class=\"burk\">正则化的反向传播公式</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T09:55:46.068565Z",
     "start_time": "2020-09-26T09:55:46.061105Z"
    }
   },
   "outputs": [],
   "source": [
    "def backer_forward_L2(Al, y, forward_model_cache, forward_parameters, lambda_num = 0.7):\n",
    "    \n",
    "    grades = {}\n",
    "    \n",
    "    l = len(forward_model_cache)\n",
    "    \n",
    "    m = y.shape[1]\n",
    "    # print('line_model_backward_m',m)\n",
    "    \n",
    "    y = y.reshape(Al.shape) # 使真实标签与预测值标签的维度保持一样方便后面的dal计算\n",
    "        \n",
    "    dal = -(np.divide(y,Al) - np.divide(1-y, 1-Al))\n",
    "    \n",
    "    # 计算最后一层的dw, db 因为最后一层使用的是sigmoid，可以直接算出dw跟db的值\n",
    "    \n",
    "    last_layer_parameters = forward_model_cache[-1]\n",
    "    \n",
    "    grades['dA'+str(l-1)], grades['dW'+str(l)], grades['db'+str(l)] = line_activation_backward(dal, last_layer_parameters, activation='sigmoid')\n",
    "    \n",
    "    grades['dW'+str(l)] = grades[\"dW\"+str(l)] + lambda_num * forward_parameters[\"W\"+str(l)] / m\n",
    "    # 这个revered函数会将循环的数进行倒置\n",
    "    \n",
    "    for i in reversed(range(1,l)):\n",
    "        grades['dA'+str(i - 1)], grades['dW'+str(i)],grades['db'+str(i)] = line_activation_backward(grades[\"dA\"+str(i)],\n",
    "                                                                                               forward_model_cache[i-1],\n",
    "                                                                                             activation = 'relu')\n",
    "        \n",
    "        \n",
    "        grades[\"dW\"+str(i - 1)] = grades['dW'+str(i)] + lambda_num * forward_parameters['W'+str(i)] / m\n",
    "        \n",
    "        # 这个for循环不会包含l的值所以这里计算的偏导数也就不包含最后一步的偏导数\n",
    "    return grades\n",
    "                                     \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T09:55:46.084368Z",
     "start_time": "2020-09-26T09:55:46.080103Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dW1 [[0.41010002 0.07807203 0.13798444 0.10502167]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.05283652 0.01005865 0.01777766 0.0135308 ]]\n",
      "db1 [[-0.22007063]\n",
      " [ 0.        ]\n",
      " [-0.02835349]]\n",
      "dA1 [[ 0.12913162 -0.44014127]\n",
      " [-0.14175655  0.48317296]\n",
      " [ 0.01663708 -0.05670698]]\n"
     ]
    }
   ],
   "source": [
    "Al, Y_assess, caches = L_model_backward_test_case()\n",
    "grads = line_model_backward(Al, Y_assess, caches)\n",
    "print('dW1',grads['dW1'])\n",
    "print('db1',grads['db1'])\n",
    "print('dA1',grads['dA1'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T09:55:46.107101Z",
     "start_time": "2020-09-26T09:55:46.103270Z"
    }
   },
   "outputs": [],
   "source": [
    "def updata_parameters(parameters, grads, learning_rate):\n",
    "    \n",
    "    L = len(parameters)//2\n",
    "    \n",
    "    for i in range(1,L+1):\n",
    "        parameters['W'+str(i)] = parameters['W' + str(i)] - grads['dW'+str(i)]*learning_rate\n",
    "        \n",
    "        parameters['b'+str(i)] = parameters['b' + str(i)] - grads['db'+str(i)]*learning_rate\n",
    "        \n",
    "    return parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T09:55:46.144525Z",
     "start_time": "2020-09-26T09:55:46.137830Z"
    }
   },
   "outputs": [],
   "source": [
    "def dnn_model(x, y, dim_info, learning_rate=0.0075, num_iterations=100, print_cost= True, lambda_num=0 ):\n",
    "    \n",
    "    np.random.seed(1)\n",
    "    costs = []\n",
    "    m = y.shape[1]\n",
    "    \n",
    "    parameters = initialize(dim_info)\n",
    "    \n",
    "    for i in range(0,num_iterations):\n",
    "        Al, forward_model_cache = line_model(x, parameters) # 向前传播的函数 // 这个向前传播函数放进cost函数当中 所以这一个函数在这里没用调用\n",
    "        \n",
    "        cost = computer_cost(Al, y) # 进行成本计算 # 因为后面把line_model函数放进了computer_cost函数当中所以computer_cost函数增加了两个参数值 (x，parametes)\n",
    "        # //~~ 去除Al参数因为在内部已经调用\n",
    "        \n",
    "        cost_L2, parameters_cost_L2 = cost_L2_tail(cost, forward_model_cache, lambda_num, m) # L2 的正向传播函数\n",
    "        \n",
    "        # grades = line_model_backward(Al, y, forward_model_cache) # 进行反向传播\n",
    "        \n",
    "        grades = backer_forward_L2(Al, y, forward_model_cache, parameters_cost_L2, lambda_num ) # 加正则化之后的反向传播公式\n",
    "        \n",
    "        parameters = updata_parameters(parameters, grades, learning_rate)\n",
    "        \n",
    "        \n",
    "        # if i % 100 == 0:\n",
    "            # if print_cost and i > 0:\n",
    "                # print('训练%i次后的成本是: %f'%(i, cost))\n",
    "            # costs.append(cost)\n",
    "            \n",
    "        if i % 100 ==0:\n",
    "            if print_cost and i > 0:\n",
    "                print(\"训练%i次后的成本是: %f\"%(i, cost_L2))\n",
    "            costs.append(cost_L2)\n",
    "    \n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations(per tens)')\n",
    "    plt.title('Learning rate ='+str(learning_rate))\n",
    "\n",
    "    plt.show()\n",
    "        \n",
    "    return parameters\n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T09:56:40.414632Z",
     "start_time": "2020-09-26T09:55:46.161925Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sandy/.local/lib/python3.7/site-packages/ipykernel_launcher.py:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练100次后的成本是: 1.086615\n",
      "训练200次后的成本是: 1.018343\n",
      "训练300次后的成本是: 0.948026\n",
      "训练400次后的成本是: 0.870058\n",
      "训练500次后的成本是: 0.827412\n",
      "训练600次后的成本是: 0.770008\n",
      "训练700次后的成本是: 0.734844\n",
      "训练800次后的成本是: 0.702187\n",
      "训练900次后的成本是: 0.700292\n",
      "训练1000次后的成本是: 0.663659\n",
      "训练1100次后的成本是: 0.646769\n",
      "训练1200次后的成本是: 0.633778\n",
      "训练1300次后的成本是: 0.623236\n",
      "训练1400次后的成本是: 0.614396\n",
      "训练1500次后的成本是: 0.606683\n",
      "训练1600次后的成本是: 0.599542\n",
      "训练1700次后的成本是: 0.600706\n",
      "训练1800次后的成本是: 0.588388\n",
      "训练1900次后的成本是: 0.583287\n",
      "训练2000次后的成本是: 0.577305\n",
      "训练2100次后的成本是: 0.572726\n",
      "训练2200次后的成本是: 0.567231\n",
      "训练2300次后的成本是: 0.563922\n",
      "训练2400次后的成本是: 0.560817\n",
      "训练2500次后的成本是: 0.557738\n",
      "训练2600次后的成本是: 0.555588\n",
      "训练2700次后的成本是: 0.553116\n",
      "训练2800次后的成本是: 0.551158\n",
      "训练2900次后的成本是: 0.548861\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dim_info = [12288, 30, 8, 6, 1]\n",
    "#dim_info = [12288, 100, 20, 10, 1]\n",
    "\n",
    "\n",
    "parameters = dnn_model(train_x, train_y, dim_info, learning_rate=0.0075, num_iterations = 3000, print_cost = True, lambda_num = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T09:56:40.423624Z",
     "start_time": "2020-09-26T09:56:40.417599Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(X,parameters):   \n",
    "    m = X.shape[1]\n",
    "    n = len(parameters) // 2 # number of layers in the neural network\n",
    "    p = np.zeros((1,m))\n",
    "    \n",
    "    # 进行一次前向传播，得到预测结果\n",
    "    probas, caches = line_model(X, parameters)\n",
    "   \n",
    "    # 将预测结果转化成0和1的形式，即大于0.5的就是1，否则就是0\n",
    "    for i in range(0, probas.shape[1]):\n",
    "        if probas[0,i] > 0.5:\n",
    "            p[0,i] = 1\n",
    "        else:\n",
    "            p[0,i] = 0\n",
    "        \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T09:56:40.438241Z",
     "start_time": "2020-09-26T09:56:40.427872Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测准确率是:0.9952153110047844\n"
     ]
    }
   ],
   "source": [
    "pred_train = predict(train_x, parameters)\n",
    "\n",
    "print('预测准确率是:'+ str(np.sum((pred_train == train_y) / train_x.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T09:56:40.451408Z",
     "start_time": "2020-09-26T09:56:40.441236Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集的准确率是:0.8200000000000001\n"
     ]
    }
   ],
   "source": [
    "pred_test = predict(test_x, parameters)\n",
    "print(\"测试集的准确率是:\"+str(np.sum((pred_test == test_y) / test_x.shape[1])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T09:56:40.458217Z",
     "start_time": "2020-09-26T09:56:40.454209Z"
    }
   },
   "outputs": [],
   "source": [
    "# 遇到的问题如下 神经网络的架构问题\n",
    "# 变量问题导致的变量冲突\n",
    "# 激活函数用错问题 在隐藏层用了sigmod激活函数，在输出层用了relu激活函数\n",
    "# 算法逻辑"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
